{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# from rsna_retro.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XentContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XentContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temp=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        bs,feat = x.shape\n",
    "        t2 = x.view(bs,1,feat)\n",
    "        \n",
    "        csim = F.cosine_similarity(x, t2, dim=-1)/self.temp\n",
    "        csim_noself = csim[~torch.eye(bs).bool()].reshape(bs, bs-1)\n",
    "        return F.cross_entropy(csim_noself, y)\n",
    "    \n",
    "\n",
    "#export\n",
    "from pytorch_metric_learning import losses\n",
    "class XentLoss(losses.NTXentLoss):\n",
    "    def forward(self, output1, output2):\n",
    "        stacked = torch.cat((output1, output2), dim=0)\n",
    "        labels = torch.arange(output1.shape[0]).repeat(2)\n",
    "        return super().forward(stacked, labels, None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XentContrastiveLoss2(nn.Module):\n",
    "    def __init__(self, temp=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, output1, output2):\n",
    "        x = torch.cat((output1, output2), dim=0)\n",
    "        bs = x.shape[0]\n",
    "        y = (torch.arange(bs, device=x.device)+bs//2-1) % (bs-1)\n",
    "        \n",
    "        bs,feat = x.shape\n",
    "        t2 = x.view(bs,1,feat)\n",
    "        \n",
    "        csim = F.cosine_similarity(x, t2, dim=-1)/self.temp\n",
    "        csim_noself = csim[~torch.eye(bs).bool()].reshape(bs, bs-1)\n",
    "        return F.cross_entropy(csim_noself, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#         xb, = self.learn.xb\n",
    "#         xb_targ = self.aug_targ(xb)\n",
    "#         xb_pos = self.aug_pos(xb)\n",
    "#         self.learn.xb = torch.cat((xb_targ, xb_pos), dim=0),\n",
    "#         bs = self.learn.xb[0].shape[0]\n",
    "#         self.learn.yb = (torch.arange(bs, device=xb.device)+bs//2-1) % (bs-1),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,feat=4,16 # \n",
    "targ = torch.randn(bs, feat) # bs x features\n",
    "rand_aug = torch.randn(bs, feat) # bs x features\n",
    "aug = targ + 0.1 # bs x feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1, o2 = targ, rand_aug\n",
    "temp = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xcl2 = XentContrastiveLoss2(temp)\n",
    "xl2 = XentLoss(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.0646), tensor(2.0646))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcl2(o1, o2), xl2(o1,o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(8).roll(4)\n",
    "t[t>=4] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs2 = bs-1; bs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3],\n",
       "        [1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6],\n",
       "        [4, 0],\n",
       "        [5, 1],\n",
       "        [6, 2],\n",
       "        [7, 3]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(bs).roll(bs//2,1)[~torch.eye(bs).bool()].reshape(bs, bs-1).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs2//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.arange(bs2//2,bs2), torch.arange(0,round(bs/2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4).repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (torch.arange(bs)+bs//2-1) % (bs-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Xent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9973, -0.5696,  0.2862, -0.1613],\n",
       "        [-0.5812,  0.9949, -0.1916,  0.0144],\n",
       "        [ 0.2550, -0.2069,  0.9969,  0.2842],\n",
       "        [-0.1879,  0.0139,  0.3300,  0.9865]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7110, 0.5657, 1.3314, 0.8510],\n",
       "        [0.5592, 2.7045, 0.8256, 1.0145],\n",
       "        [1.2905, 0.8131, 2.7098, 1.3287],\n",
       "        [0.8287, 1.0140, 1.3910, 2.6817]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cexp = torch.exp(cos_sim)\n",
    "cexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.4592, 5.1039, 6.1420, 5.9154])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cexp.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7481, 2.3994, 3.4322, 3.2337])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_denom = (cexp*(1-labels)).sum(dim=-1); neg_denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9973, 0.9949, 0.9969, 0.9865])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = cos_sim[range(lmax.shape[0]),lmax]; pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7481, 2.3994, 3.4322, 3.2337])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cexp.sum(dim=-1) - torch.exp(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0136, -1.4448, -0.9470, -1.3350],\n",
       "        [-1.5921,  0.1197, -1.4248, -1.1592],\n",
       "        [-0.7559, -1.0821, -0.2363, -0.8895],\n",
       "        [-1.1988, -0.8613, -0.9032, -0.1872]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoft2 = torch.log(cexp/neg_denom); lsoft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2509)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_nll = torch.mean(torch.sum(-lmax * lsoft2, dim=1)); l_nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7110, 0.5657, 1.3314, 0.8510],\n",
       "        [0.5592, 2.7045, 0.8256, 1.0145],\n",
       "        [1.2905, 0.8131, 2.7098, 1.3287],\n",
       "        [0.8287, 1.0140, 1.3910, 2.6817]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = 1.0\n",
    "cos_sim = F.cosine_similarity(output1, output2, dim=-1)/temp\n",
    "cexp = torch.exp(cos_sim)\n",
    "cexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7110, 2.7045, 2.7098, 2.6817])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (cexp * labels).sum(dim=-1); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7481, 2.3994, 3.4322, 3.2337])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cexp*(1-labels)).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7481, 2.3994, 3.4322, 3.2337])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denom = cexp.sum(dim=-1) - x; denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0136,  1.4448,  0.9470,  1.3350],\n",
       "        [ 1.5921, -0.1197,  1.4248,  1.1592],\n",
       "        [ 0.7559,  1.0821,  0.2363,  0.8895],\n",
       "        [ 1.1988,  0.8613,  0.9032,  0.1872]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoft = -torch.log(cexp/denom)\n",
    "lsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0136, -0.1197,  0.2363,  0.1872])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(x)+torch.log(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0136, -0.1197,  0.2363,  0.1872])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_denom = (cexp*(1-labels)).sum(dim=-1); neg_denom\n",
    "lsoft1 = torch.log(cexp/neg_denom)\n",
    "lsoft2 = torch.sum(-labels * lsoft1, dim=-1)\n",
    "lsoft2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sim_mat(x, y=None):\n",
    "    \"\"\"\n",
    "    returns a matrix where entry (i,j) is the dot product of x[i] and x[j]\n",
    "    \"\"\"\n",
    "    if y is None:\n",
    "        y = x\n",
    "    return torch.matmul(x, y.t())\n",
    "\n",
    "def convert_to_pairs(indices_tuple, labels):\n",
    "    \"\"\"\n",
    "    This returns anchor-positive and anchor-negative indices,\n",
    "    regardless of what the input indices_tuple is\n",
    "    Args:\n",
    "        indices_tuple: tuple of tensors. Each tensor is 1d and specifies indices\n",
    "                        within a batch\n",
    "        labels: a tensor which has the label for each element in a batch\n",
    "    \"\"\"\n",
    "    if indices_tuple is None:\n",
    "        return get_all_pairs_indices(labels)\n",
    "    elif len(indices_tuple) == 4:\n",
    "        return indices_tuple\n",
    "    else:\n",
    "        a, p, n = indices_tuple\n",
    "        return a, p, a, n\n",
    "\n",
    "def get_all_pairs_indices(labels, ref_labels=None):\n",
    "    \"\"\"\n",
    "    Given a tensor of labels, this will return 4 tensors.\n",
    "    The first 2 tensors are the indices which form all positive pairs\n",
    "    The second 2 tensors are the indices which form all negative pairs\n",
    "    \"\"\"\n",
    "    if ref_labels is None:\n",
    "        ref_labels = labels\n",
    "    labels1 = labels.unsqueeze(1)\n",
    "    labels2 = ref_labels.unsqueeze(0)\n",
    "    matches = (labels1 == labels2).byte()\n",
    "    diffs = matches ^ 1\n",
    "    if ref_labels is labels:\n",
    "        matches -= torch.eye(matches.size(0)).byte().to(labels.device)\n",
    "    a1_idx = matches.nonzero()[:, 0].flatten()\n",
    "    p_idx = matches.nonzero()[:, 1].flatten()\n",
    "    a2_idx = diffs.nonzero()[:, 0].flatten()\n",
    "    n_idx = diffs.nonzero()[:, 1].flatten()\n",
    "    return a1_idx, p_idx, a2_idx, n_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss2(nn.Module):\n",
    "\n",
    "    def __init__(self, temperature, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.temperature = temperature\n",
    "        self.normalize_embeddings = True\n",
    "\n",
    "    def forward(self, embeddings, labels, indices_tuple):\n",
    "        cosine_similarity = sim_mat(embeddings)\n",
    "        if not self.normalize_embeddings:\n",
    "            embedding_norms_mat = self.embedding_norms.unsqueeze(0)*self.embedding_norms.unsqueeze(1)\n",
    "            cosine_similarity = cosine_similarity / (embedding_norms_mat)\n",
    "        cosine_similarity = cosine_similarity / self.temperature\n",
    "\n",
    "        a1, p, a2, n = convert_to_pairs(indices_tuple, labels)\n",
    "\n",
    "        if len(a1) > 0 and len(a2) > 0:\n",
    "            pos_pairs = cosine_similarity[a1, p].unsqueeze(1)\n",
    "            neg_pairs = cosine_similarity[a2, n]\n",
    "            n_per_p = (a2.unsqueeze(0) == a1.unsqueeze(1)).float()\n",
    "            neg_pairs = neg_pairs*n_per_p\n",
    "            neg_pairs[n_per_p==0] = float('-inf')\n",
    "\n",
    "            max_val = torch.max(pos_pairs, torch.max(neg_pairs, dim=1, keepdim=True)[0])\n",
    "            numerator = torch.exp(pos_pairs - max_val).squeeze(1)\n",
    "            denominator = torch.sum(torch.exp(neg_pairs - max_val), dim=1) + numerator\n",
    "            log_exp = torch.log((numerator/denominator) + 1e-20)\n",
    "            return torch.mean(-log_exp)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'NTXentLoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-9e98ec61d774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNTXentLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'NTXentLoss'"
     ]
    }
   ],
   "source": [
    "ml = losses.NTXentLoss(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.cat((targ, rand_aug), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.arange(targ.shape[0]).repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " tensor([4, 5, 6, 7, 0, 1, 2, 3]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "         4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7]),\n",
       " tensor([1, 2, 3, 5, 6, 7, 0, 2, 3, 4, 6, 7, 0, 1, 3, 4, 5, 7, 0, 1, 2, 4, 5, 6,\n",
       "         1, 2, 3, 5, 6, 7, 0, 2, 3, 4, 6, 7, 0, 1, 3, 4, 5, 7, 0, 1, 2, 4, 5, 6]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_pairs_indices(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pytorch_metric_learning import losses\n",
    "class XentLoss(losses.NTXentLoss):\n",
    "    def forward(self, output1, output2):\n",
    "        stacked = torch.cat((output1, output2), dim=0)\n",
    "        labels = torch.arange(output1.shape[0]).repeat(2)\n",
    "        return super().forward(stacked, labels, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8078)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml(stacked, labels, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it into code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://arxiv.org/pdf/2002.05709.pdf\n",
    "class XentContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temp=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, output1, output2, labels):\n",
    "        cos_sim = F.cosine_similarity(output1, output2, dim=-1)/self.temp\n",
    "        cexp = torch.exp(cos_sim)\n",
    "        neg_denom = (cexp*(1-labels)).sum(dim=-1)\n",
    "        lsoft = torch.log(cexp/neg_denom)\n",
    "        lsoft = torch.sum(-labels * lsoft, dim=-1)\n",
    "        print(lsoft)\n",
    "        return lsoft.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class XentContrastiveLoss2(nn.Module):\n",
    "    def __init__(self, temp=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, output1, output2, labels):\n",
    "        cos_sim = F.cosine_similarity(output1, output2, dim=-1)/self.temp\n",
    "        cexp = torch.exp(cos_sim)\n",
    "        x = (cexp * labels).sum(dim=-1)\n",
    "        denom = cexp.sum(dim=-1) - x\n",
    "        lsoft = -torch.log(x/denom)\n",
    "        print(lsoft)\n",
    "        return lsoft.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchContrastiveLoss(nn.Module):\n",
    "    def __init__(self, loss_func):\n",
    "        super().__init__()\n",
    "        self.loss_func = loss_func\n",
    "        self.onehot = not isinstance(loss_func, XentOldContrastiveLoss)\n",
    "        \n",
    "    def forward(self, output1, output2):\n",
    "        output1, output2, labels = batched_labels(output1, output2, self.onehot)\n",
    "        return self.loss_func(output1, output2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.1\n",
    "ls2 = {\n",
    "#     '1_contloss': ContrastiveLoss(margin=1.0),\n",
    "    '4_xentloss': XentContrastiveLoss(temp=temp),\n",
    "    '5_xentloss2': XentContrastiveLoss2(temp=temp),\n",
    "    '6_oldxentloss': XentOldContrastiveLoss(temp=temp)\n",
    "}\n",
    "\n",
    "def batch_loss_out(t,a):\n",
    "    return {k:BatchContrastiveLoss(v)(t,a) for k,v in ls2.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,feat=16,128 # \n",
    "targ = torch.randn(bs, feat) # bs x features\n",
    "rand_aug = torch.randn(bs, feat) # bs x features\n",
    "aug = targ + 0.05 # bs x feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_xentloss': tensor(-6.8875),\n",
       " '5_xentloss2': tensor(-6.8876),\n",
       " '6_oldxentloss': tensor(0.0010)}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss_out(targ,targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_xentloss': tensor(3.4285),\n",
       " '5_xentloss2': tensor(3.4285),\n",
       " '6_oldxentloss': tensor(3.4732)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss_out(targ,rand_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_xentloss': tensor(7.5412),\n",
       " '5_xentloss2': tensor(7.5412),\n",
       " '6_oldxentloss': tensor(7.5418)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,feat=256,256 # \n",
    "targ = torch.randn(bs, feat) # bs x features\n",
    "aug = targ+0.1 # bs x features\n",
    "rand_aug = torch.randn(bs, feat) # bs x features\n",
    "batch_loss_out(targ,-aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_metadata.ipynb.\n",
      "Converted 01_preprocess.ipynb.\n",
      "Converted 01_preprocess_mean_std.ipynb.\n",
      "Converted 02_train.ipynb.\n",
      "Converted 02_train_01_save_features.ipynb.\n",
      "Converted 03_train3d.ipynb.\n",
      "Converted 04_trainfull3d_deprecated.ipynb.\n",
      "Converted 04_trainfull3d_labels.ipynb.\n",
      "Converted 05_train_adjacent.ipynb.\n",
      "Converted 06_seutao_features.ipynb.\n",
      "Converted 07_adni.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "#\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "Converted 07_adni_01.ipynb.\n",
      "Converted 08_contrastive_loss-Copy1.ipynb.\n",
      "Converted 08_contrastive_loss.ipynb.\n",
      "Converted 08_imagewang.ipynb.\n",
      "Converted 08_train_self_supervised.ipynb.\n",
      "Converted 08_train_self_supervised_train_1.ipynb.\n",
      "Converted 08_train_self_supervised_train_2_nocombined.ipynb.\n",
      "Converted 08_train_self_supervised_train_2_nocombined_contrast.ipynb.\n",
      "Converted 08_train_self_supervised_train_3.ipynb.\n",
      "Converted 08_train_self_supervised_train_4_nocombined_xent-Copy1.ipynb.\n",
      "Converted 08_train_self_supervised_train_4_nocombined_xent.ipynb.\n",
      "Converted 09_ImageWang_Leadboard_128.ipynb.\n",
      "Converted 09_ImageWang_Leadboard_SS.ipynb.\n",
      "Converted 09_ImageWang_Leadboard_SS_1.ipynb.\n",
      "Converted 09_ImageWang_Leadboard_SS_2.ipynb.\n",
      "Converted Tabular_02_FeatureImportance.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted Untitled1.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
